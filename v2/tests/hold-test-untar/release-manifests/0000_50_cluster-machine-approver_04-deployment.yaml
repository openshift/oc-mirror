apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: openshift-cluster-machine-approver
  name: machine-approver
  labels:
    app: machine-approver
    machine-approver: "true"
  annotations:
    exclude.release.openshift.io/internal-openshift-hosted: "true"
    include.release.openshift.io/self-managed-high-availability: "true"
    include.release.openshift.io/single-node-developer: "true"
    kubectl.kubernetes.io/default-container: machine-approver-controller
spec:
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: machine-approver
  template:
    metadata:
      name: machine-approver
      annotations:
        target.workload.openshift.io/management: '{"effect": "PreferredDuringScheduling"}'
      labels:
        app: machine-approver
    spec:
      hostNetwork: true
      serviceAccountName: machine-approver-sa
      containers:
      - args:
        - --secure-listen-address=0.0.0.0:9192
        - --upstream=http://127.0.0.1:9191/
        - --tls-cert-file=/etc/tls/private/tls.crt
        - --tls-private-key-file=/etc/tls/private/tls.key
        - --config-file=/etc/kube-rbac-proxy/config-file.yaml
        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305
        - --logtostderr=true
        - --v=3
        image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:c28f27a3a10df13e5e8c074e8734683a6603ebaccd9d67e2095070fb6859b1d6
        imagePullPolicy: IfNotPresent
        name: kube-rbac-proxy
        ports:
        - containerPort: 9192
          name: https
          protocol: TCP
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        resources:
          requests:
            memory: 20Mi
            cpu: 10m
        volumeMounts:
        - mountPath: /etc/kube-rbac-proxy
          name: auth-proxy-config
        - mountPath: /etc/tls/private
          name: machine-approver-tls
      - name: machine-approver-controller
        image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:ec53f44c080dc784adb01a4e3b8257adffaf79a6e38f683d26bf1b384d6b7156
        imagePullPolicy: IfNotPresent
        command: ["/usr/bin/machine-approver"]
        args:
        - "--config=/var/run/configmaps/config/config.yaml"
        - "-v=2"
        - "--logtostderr"
        - "--leader-elect=true"
        - "--leader-elect-lease-duration=137s"
        - "--leader-elect-renew-deadline=107s"
        - "--leader-elect-retry-period=26s"
        - "--leader-elect-resource-namespace=openshift-cluster-machine-approver"
        - "--api-group-version=machine.openshift.io/v1beta1"
        resources:
          requests:
            memory: 50Mi
            cpu: 10m
        volumeMounts:
        - mountPath: /var/run/configmaps/config
          name: config
        env:
        - name: RELEASE_VERSION
          value: "4.12.0"
        - name: METRICS_PORT
          value: "9191"
        terminationMessagePolicy: FallbackToLogsOnError
      volumes:
      - configMap:
          name: kube-rbac-proxy
        name: auth-proxy-config
      - name: machine-approver-tls
        secret:
          secretName: machine-approver-tls
      - name: config
        configMap:
          defaultMode: 440
          name: machine-approver-config
          optional: true
      nodeSelector:
        node-role.kubernetes.io/master: ""
      priorityClassName: "system-cluster-critical"
      tolerations:
      - key: node-role.kubernetes.io/master  # Just tolerate NoSchedule taint on master node. If there are other conditions like disk-pressure etc, let's not schedule the control-plane pods onto that node.
        operator: Exists
        effect: "NoSchedule"
      - key: "node.kubernetes.io/unreachable"
        operator: "Exists"
        effect: "NoExecute"
        tolerationSeconds: 120 # Evict pods within 2 mins.
      - key: "node.kubernetes.io/not-ready"
        operator: "Exists"
        effect: "NoExecute"
        tolerationSeconds: 120 # Evict pods within 2 mins.
